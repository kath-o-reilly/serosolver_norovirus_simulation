data$x1997_ic50r <- as.numeric(data$x1997_ic50>5)
table(data$x2012_ic50r,useNA = "ifany")
table(data$x2009_ic50r,useNA = "ifany")
table(data$x2006b_ic50r,useNA = "ifany")
table(data$x2002_ic50r,useNA = "ifany")
table(data$x1997_ic50r,useNA = "ifany")  # Lisa says not to anlayse these ones further
data$present <- as.numeric(!is.na(data$x2012_ic50r)) + as.numeric(!is.na(data$x2009_ic50r)) + as.numeric(!is.na(data$x2006b_ic50r)) + as.numeric(!is.na(data$x2002_ic50r))
data$resp_num <- as.numeric(data$x2012_ic50r) + as.numeric(data$x2009_ic50r) + as.numeric(data$x2006b_ic50r) + as.numeric(data$x2002_ic50r)
table(data$present)
table(data$resp_num)
# so we will restrict data to those with ALL sera available
# note that some of the very young sera is more likely to be incomplete.
data <- data %>% filter(present==4)
# group age
age_gp <- c(0,2,3,4,5,6,7)
data$age_gp <- cut(data$age,breaks=age_gp,labels=c(1:6),right=F)
#table(data$age,data$age_gp)
tmp <- as.matrix(table(age=data$age_gp,coll=data$yearof_collection))
tmp2 <- matrix(NA,nrow=7,ncol=6)
tmp2[1:6,1:5] <- tmp
tmp2[,6] <- c(rowSums(tmp),0)
tmp2[7,] <- colSums(tmp2,na.rm=T)
tmp2
row.names(tmp2) <- c(1:6,"total")
colnames(tmp2) <- c(2008:2012,"total")
write.table(tmp2,paste0(data_folder,"ddump.csv"),sep=",")
names(data)
# correlations
tmp <- data %>% filter(resp_num>0)
cor.test(tmp$x2012_ic50,tmp$x2009_ic50)
tab <- data %>% group_by(age_gp,yearof_collection) %>% summarize(n=n(),
x2012_ic50r = sum(x2012_ic50r),
x2009_ic50r = sum(x2009_ic50r),
x2006b_ic50r = sum(x2006b_ic50r),
x2002_ic50r = sum(x2002_ic50r),
any = sum(resp_num>=1),
x2012_ic50rpt = sum(x2012_ic50r)/n(),
x2009_ic50rpt = sum(x2009_ic50r)/n(),
x2006b_ic50rpt = sum(x2006b_ic50r)/n(),
x2002_ic50rpt = sum(x2002_ic50r)/n())
# we want to output tab for cat model analysis later on
write.csv(tab,paste0(out_folder,"responder_data_agg_22Apr22.csv"),row.names = F)
tab2 <- tab %>% gather('x2002_ic50rpt','x2006b_ic50rpt','x2009_ic50rpt','x2012_ic50rpt',key="blockade",value="respond")
head(tab2)
tab2$block_lab <- tab2$blockade
# tab2$block_lab <- recode(tab2$block_lab,
#                          x2002_ic50rpt = "Farm Hills (2002)",
#                          x2006b_ic50rpt = "Den Haag (2006)",
#                          x2009_ic50rpt = "New Orleans (2009)",
#                          x2012_ic50rpt = "Sydney (2012)")
tab2$block_lab <- recode(tab2$block_lab,
x2002_ic50rpt = "FH 2002",
x2006b_ic50rpt = "DH 2006",
x2009_ic50rpt = "NO 2009",
x2012_ic50rpt = "SY 2012")
levels(tab2$block_lab)
tab2$block_lab <- factor(tab2$block_lab, levels=c('FH 2002','DH 2006','NO 2009','SY 2012'))
tab3 <- data %>% group_by(age_gp) %>% summarize(n=n(),
x2012_ic50rpt = sum(x2012_ic50r)/n(),
x2009_ic50rpt = sum(x2009_ic50r)/n(),
x2006b_ic50rpt = sum(x2006b_ic50r)/n(),
x2002_ic50rpt = sum(x2002_ic50r)/n(),
any = sum(resp_num>=1),
any_pt = sum(sum(resp_num>=1))/n())
tab3$yearof_collection <- "NA"
# does a time series work better?
p3 <- ggplot(tab2,aes(x=age_gp,y=respond,color=as.factor(yearof_collection),group=yearof_collection)) +
geom_point() + geom_line() + facet_wrap(~block_lab) +
scale_color_discrete("Year of\ncollection",type=brewer.pal(5, "Dark2")) +
ylab("Proportion of Participants with a Response") +
xlab("Age of Participant (Yrs)") +
theme_bw() + theme(text=element_text(family="Open Sans"))
# we want to restrict the analysis to those that are "responders"
data$response <- data$x2012_ic50r + data$x2009_ic50r + data$x2006b_ic50r + data$x2002_ic50r
table(data$response)
# compare relative IC50s for specific groups (wip)
data3 <- data %>% filter(response!=0)
data3$date2 <- as.Date(data3$sample_date,origin = "1900-01-01")
data3$mth <- format(data3$date2,"%b")
table(data3$mth)
data4 <- data3 #%>% filter(mth !="Dec" & mth !="Jan" & mth !="Feb" )
tmp <- data3 %>% select(x2012_ic50,x2012_slope,age,mth,yearof_collection)
View(tmp)
res.km <- kmeans(scale(tmp[, -5]), 3, nstart = 25)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_slope <- as.numeric(tmp$x2012_slope)
res.km <- kmeans(scale(tmp[, -5]), 3, nstart = 25)
tmp$mth <- as.numeric(tmp$mth)
data3$mth <- format(data3$date2,"%m")
tmp <- data3 %>% select(x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_slope <- as.numeric(tmp$x2012_slope)
res.km <- kmeans(scale(tmp[, -5]), 3, nstart = 25)
tmp <- tmp[!is.na(tmp$x2012_ic50),]
tmp <- tmp[!is.na(tmp$x2012_slope),]
tmp <- tmp[!is.na(tmp$mth),]
res.km <- kmeans(scale(tmp[, -5]), 3, nstart = 25)
colMeans(tmp)
mean(tmp$x2012_ic50)
mean(tmp$x2012_slope)
mean(tmp$age)
mean(tmp$mth)
!is.na(tmp$mth)
tmp$mth <- as.numeric(tmp$mth)
colMeans(tmp)
res.km <- kmeans(scale(tmp[, -5]), 3, nstart = 25)
fviz_cluster(res.km, data = df[, -5],
#palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
library(ggpubr)
library(factoextra)
fviz_cluster(res.km, data = df[, -5],
#palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
fviz_cluster(res.km, data = tmp[, -5],
#palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
# Dimension reduction using PCA
res.pca <- prcomp(tmp[, -5],  scale = TRUE)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)
# Add Species groups from the original data sett
ind.coord$Species <- tmp$yearof_collection
# Data inspection
head(ind.coord)
# Percentage of variance explained by dimensions
eigenvalue <- round(get_eigenvalue(res.pca), 1)
variance.percent <- eigenvalue$variance.percent
head(eigenvalue)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Species", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) +
stat_mean(aes(color = cluster), size = 4)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "yearof_collection", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) +
stat_mean(aes(color = cluster), size = 4)
View(ind.coord)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Species", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) +
stat_mean(aes(color = cluster), size = 4)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Species", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) #+
# Add Species groups from the original data sett
ind.coord$Species <- as.factor(tmp$yearof_collection)
# Data inspection
head(ind.coord)
# Percentage of variance explained by dimensions
eigenvalue <- round(get_eigenvalue(res.pca), 1)
variance.percent <- eigenvalue$variance.percent
head(eigenvalue)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Species", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) #+
names(data3)
tmp <- data3 %>% select(x2009_ic50,x2009_slope,x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_slope <- as.numeric(tmp$x2012_slope)
tmp$mth <- as.numeric(tmp$mth)
tmp <- data3 %>% select(as.numeric(x2009_ic50),as.numeric(x2009_slope),x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp <- data3 %>% select(x2009_ic50,x2009_slope,x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_slope <- as.numeric(tmp$x2012_slope)
tmp$x2009_ic50 <- as.numeric(tmp$x2009_ic50)
tmp$x2009_slope <- as.numeric(tmp$x2009_slope)
tmp <- tmp[!is.na(tmp$x2012_ic50),]
tmp <- tmp[!is.na(tmp$x2012_slope),]
tmp <- tmp[!is.na(tmp$x2009_ic50),]
tmp <- tmp[!is.na(tmp$x2009_slope),]
tmp <- tmp[!is.na(tmp$mth),]
colMeans(tmp)
tmp$mth <- as.numeric(tmp$mth)
colMeans(tmp)
# Dimension reduction using PCA
res.pca <- prcomp(tmp[, -7],  scale = TRUE)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)
res.km <- kmeans(scale(tmp[, -7]), 5, nstart = 25)
# Dimension reduction using PCA
res.pca <- prcomp(tmp[, -7],  scale = TRUE)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)
# Add Species groups from the original data sett
ind.coord$Year <- as.factor(tmp$yearof_collection)
# Data inspection
head(ind.coord)
# Percentage of variance explained by dimensions
eigenvalue <- round(get_eigenvalue(res.pca), 1)
variance.percent <- eigenvalue$variance.percent
head(eigenvalue)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Year", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) #+
head(data3)
names(data3)
tmp <- data3 %>% select(x2006b_ic50,x2006b_slope,x2009_ic50,x2009_slope,x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp$x2006b_ic50 <- as.numeric(tmp$x2006b_ic50)
tmp$x2006b_slope <- as.numeric(tmp$x2006b_slope)
tmp$mth <- as.numeric(tmp$mth)
tmp <- tmp[!is.na(tmp$x2012_ic50),]
tmp <- tmp[!is.na(tmp$x2012_slope),]
tmp <- tmp[!is.na(tmp$x2009_ic50),]
tmp <- tmp[!is.na(tmp$x2009_slope),]
tmp <- tmp[!is.na(tmp$mth),]
colMeans(tmp)
tmp <- tmp[!is.na(tmp$x2006b_ic50),]
tmp <- tmp[!is.na(tmp$x2006b_slope),]
tmp <- tmp[!is.na(tmp$mth),]
colMeans(tmp)
tmp$mth <- as.numeric(tmp$mth)
tmp <- tmp[!is.na(tmp$x2012_ic50),]
tmp <- tmp[!is.na(tmp$x2012_slope),]
tmp <- tmp[!is.na(tmp$x2009_ic50),]
tmp <- tmp[!is.na(tmp$x2009_slope),]
tmp <- tmp[!is.na(tmp$x2006b_ic50),]
tmp <- tmp[!is.na(tmp$x2006b_slope),]
tmp <- tmp[!is.na(tmp$mth),]
colMeans(tmp)
tmp <- data3 %>% select(x2006b_ic50,x2006b_slope,x2009_ic50,x2009_slope,x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_slope <- as.numeric(tmp$x2012_slope)
tmp$x2009_ic50 <- as.numeric(tmp$x2009_ic50)
tmp$x2009_slope <- as.numeric(tmp$x2009_slope)
tmp$x2006b_ic50 <- as.numeric(tmp$x2006b_ic50)
tmp$x2006b_slope <- as.numeric(tmp$x2006b_slope)
tmp$mth <- as.numeric(tmp$mth)
tmp <- tmp[!is.na(tmp$x2012_ic50),]
tmp <- tmp[!is.na(tmp$x2012_slope),]
tmp <- tmp[!is.na(tmp$x2009_ic50),]
tmp <- tmp[!is.na(tmp$x2009_slope),]
tmp <- tmp[!is.na(tmp$x2006b_ic50),]
tmp <- tmp[!is.na(tmp$x2006b_slope),]
tmp <- tmp[!is.na(tmp$mth),]
colMeans(tmp)
res.km <- kmeans(scale(tmp[, -9]), 5, nstart = 25)
# Dimension reduction using PCA
res.pca <- prcomp(tmp[, -9],  scale = TRUE)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)
# Add Species groups from the original data sett
ind.coord$Year <- as.factor(tmp$yearof_collection)
# Data inspection
head(ind.coord)
# Percentage of variance explained by dimensions
eigenvalue <- round(get_eigenvalue(res.pca), 1)
variance.percent <- eigenvalue$variance.percent
head(eigenvalue)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Year", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) #+
head(eigenvalue)
# Data inspection
head(ind.coord)
fviz_pca_var(res.pca,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
p1 <- ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Year", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) #+
p2 <- fviz_pca_var(res.pca,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
pdf(paste0(out_folder,"pca_summary.pdf"),height=6,width=15)
plot_grid(p1,p2,cols=2)
dev.off()
(62/122)/(54/145)
(10/122)/(16/145)
(137/274)/(143/313)
(137/274)/(26/313)
(27/274)/(26/313)
54/145
1-(1-0.37)**2
1-(1-0.37)**3
2400*3
1-(1-0.37)**4
2400*4
62/122
2400+1800
1-(1-0.51)**2
4200+2400
1-(1-0.51)**3
6600+2400
table(rbinom(1000,4,0.34))
table(rbinom(1000,4,0.22))
install.packages(c("boot", "foreign", "Matrix", "nlme"))
ages <- c(28.1,27.5,25,29.9,29.7,29.9,39.9,33.6,21.3,30.8)
bs1 <- lapply(1:1039, function(i) sample(ages, replace = T))
bs1 <- lapply(1:1039, sample(ages, replace = T))
bs2 <- sapply(1:1039, sample(ages, replace = T))
bs2 <- sapply(1:1039, function(i) sample(ages, replace = T))
View(bs2)
(log(0.5)-log(0.22))/log(0.78)
((log(0.5)-log(0.22))/log(0.78))+1
choose(20,1)
((log(0.5)-log(0.22)-log(choose(3:15,1)))/log(0.78))+1
y <- ((log(0.5)-log(0.22)-log(choose(3:15,1)))/log(0.78))+1
x<-c(3:15)
plot(x,y)
hist(rbinom(100,3,0.22))
hist(rbinom(100,3,0.22),breaks = c(0:3))
table(rbinom(100,3,0.22))/100
table(rbinom(100,6,0.22))/100
table(rbinom(100,9,0.22))/100
table(rbinom(100,9,0.22))/100
table(rbinom(1000,9,0.22))/1000
table(rbinom(1000,6,0.22))/1000
0.46*207000000
library(ggplot2)
library(coda)
library(plyr)
library(reshape2)
library(data.table)
library(foreach)
library(doParallel)
library(parallel)
library(dplyr)
library(readr)
library(viridis)
library(ggpubr)
#serosolver_wd <- "~/Documents/GitHub/serosolver/"
#devtools::load_all(serosolver_wd)
library(serosolver)
rm(list = ls())
run_name <- "sim_noro"
main_wd <-  "/Users/lsh1603970/GitHub/serosolver_norovirus_simulation" #"~/Documents/norovirus_test/"
chain_wd <- paste0(main_wd,"/chains/",run_name)
save_wd <- paste0(main_wd,"/figures/chain_plots/")
if(!dir.exists(save_wd)) dir.create(save_wd,recursive = TRUE)
if(!dir.exists(chain_wd)) dir.create(chain_wd,recursive = TRUE)
buckets <- 1 ## Ignore
prior_version <- 2 ## Which prior on the infection histories to use? Prior version 2 is generally preferred
n_chains <- 3 ## Number of MCMC chains to run
rerun <- TRUE ## Set to FALSE if you just want to load in previously run chains
setwd(main_wd)
print(paste0("In directory: ", main_wd))
print(paste0("Saving to: ", save_wd))
set.seed(1)
## Run multiple chains in parallel
cl <- makeCluster(n_chains)
registerDoParallel(cl)
## MCMC settings, not super important but can be tweaked
mcmc_pars <- c("save_block"=100,"thin"=100,"thin_hist"=500,"iterations"=100000,
"adaptive_period"=50000,
"burnin"=0,"switch_sample"=2,"hist_switch_prob"=0.05,
"year_swap_propn"=0.8,"swap_propn"=0.5,
"inf_propn"=0.5,"hist_sample_prob"=1,"move_size"=3, "hist_opt"=0,
"popt"=0.44,"popt_hist"=0.44,"opt_freq"=2000,propose_from_prior=TRUE)
## Simulation parameters
n_indivs <- 250
n_groups <- 1 ## Leave as 1, can in theory make multiple groups with distinct FOI parameters, but needs extra setup
n_samps <- 1 ## Number of samples per person
repeats <- 1 ## Number of repeat measurements per variant/sample combination
samp_min <- 2009 ## First sample year
samp_max <- 2012 ## Final sample year
year_min <- 2000 ## First year of possible circulation (ie. time 0 of the simulation)
year_max <- 2012 ## Final year of possible circulation
age_min <- 1 ## Age minimum and maximum in years, simulated from a uniform distribution
age_max <- 10
## Viruses and times for samples
sampled_viruses <- c(2000,2002,2006,2009,2012)
sampling_times <- seq(samp_min, samp_max, by=1)
## Create a fake antigenic map -- can put in what you like here
antigenic_coords <- data.frame(Strain=c(2000,2002,2006,2009,2012),X=c(0,0.5,3,3.5,4),Y=c(0,2,1,3,4))
antigenic_map <- generate_antigenic_map_flexible(antigenic_coords,
year_max=2013,year_min=2000,spar = 0.001)
ggplot(data=antigenic_map,aes(x=x_coord,y=y_coord)) + geom_line() +
geom_point(data=antigenic_coords,aes(x=X,y=Y)) +
geom_text(data=antigenic_coords,aes(x=X+0.2,y=Y,label=Strain))
strain_isolation_times <- antigenic_map$inf_times
n_times <- length(strain_isolation_times)
## Set up parameter table
par_tab <- read.csv("par_tab_base.csv",stringsAsFactors=FALSE)
par_tab <- par_tab[par_tab$names != "phi",]
par_tab[par_tab$names == c("alpha","beta"),c("values")] <- c(1/3,1/3) ## Can also try c(1,1), or something informative. Just the parameters of a beta distribution which acts as the prior on the per-time attack rate.
## Just some setup of the parameter table to get parameters vaguely like you showed me
par_tab$fixed <- 1
par_tab[par_tab$names %in% c("mu","tau","sigma1","error"),"fixed"] <- 0
par_tab[par_tab$names %in% c("mu","tau","sigma1","error"),"values"] <- c(3,0.5,0.2,2)
par_tab[par_tab$names %in% c("mu_short","sigma2"),"values"] <- c(0,1)
## Create some random measurement offsets -- these add a systematic shift to each observed variant. Only those sampled variant years have offsets, the rest are 0
## These are unknown parameters to be estimated, assuming the offsets are drawn from ~ norm(0, 1)
par_tab_rhos <- data.frame(names="rho",values=rep(0,n_times),fixed=1,steps=0.1,
lower_bound=-3,upper_bound=3,lower_start=-1,
upper_start=1,type=3)
par_tab_rhos[which(strain_isolation_times%in%sampled_viruses),"values"] <- rnorm(length(sampled_viruses), 1)
par_tab_rhos[which(strain_isolation_times%in%sampled_viruses),"fixed"] <-0
measurement_indices <- seq_along(strain_isolation_times)
par_tab <- bind_rows(par_tab, par_tab_rhos)
## Simulate realistic-ish attack rates
attack_rates <- simulate_attack_rates(strain_isolation_times, 0.15,1,FALSE)
attack_rates[attack_rates>1] <- 1
plot(strain_isolation_times,attack_rates,pch=19)
## Simulate the data
sim_data <- simulate_data(par_tab=par_tab, group=1, n_indiv=n_indivs,
buckets=buckets,
strain_isolation_times=strain_isolation_times,
measured_strains=sampled_viruses,
sampling_times=sampling_times, nsamps=n_samps,
antigenic_map=antigenic_map,
titre_sensoring=0.2, ## Randomly censor 20% of measurements
age_min=age_min,age_max=age_max,
attack_rates=attack_rates, repeats=repeats,
mu_indices = NULL, measurement_indices = measurement_indices,
add_noise=TRUE)
sum(sim_data$infection_histories)
plot_data(sim_data$data,sim_data$infection_histories,strain_isolation_times,n_indivs=10)
titre_dat <- sim_data$data %>% tidyr::drop_na()
titre_dat <- titre_dat %>% group_by(individual, samples, virus) %>% mutate(run=1:n()) %>% ungroup()
titre_dat <- titre_dat %>% left_join(sim_data$ages)
titre_dat <- titre_dat %>% arrange(individual, samples, virus, run) %>% as.data.frame()
ggplot(titre_dat,aes(x=samples,y=titre,group=samples)) + geom_boxplot() + facet_wrap(~virus)
## Save titre data
write_csv(titre_dat, file=paste0(save_wd,"/",run_name,"_titre_data.csv"))
## Save parameter table
write_csv(par_tab, file=paste0(save_wd,"/",run_name,"_par_tab.csv"))
## Save attack rates
write_csv(sim_data$attack_rates, file=paste0(save_wd,"/",run_name,"_attack_rates.csv"))
## Save infection histories
write_csv(as.data.frame(sim_data$infection_histories), file=paste0(save_wd,"/",run_name,"_infection_histories.csv"))
head(titre_dat)
table(samp=titre_dat$samples,virus=titre_dat$virus)
f <- create_posterior_func(par_tab,titre_dat,antigenic_map=antigenic_map,strain_isolation_times = strain_isolation_times,
version=prior_version,solve_likelihood=TRUE,n_alive=NULL,
measurement_indices_by_time=measurement_indices ## NULL
)
t1 <- Sys.time()
filenames <- paste0(chain_wd, "/",run_name, "_",1:n_chains)
if(rerun){
res <- foreach(x = filenames, .packages = c('serosolver','data.table','plyr',"dplyr")) %dopar% {
devtools::load_all(save_wd)
index <- 1
lik <- -Inf
inf_hist_correct <- 1
while((!is.finite(lik) || inf_hist_correct > 0) & index < 100){
start_tab <- generate_start_tab(par_tab)
start_inf <- setup_infection_histories_total(titre_dat,strain_isolation_times,2,3)
inf_hist_correct <- sum(check_inf_hist(titre_dat, strain_isolation_times, start_inf))
y <- f(start_tab$values, start_inf)
lik <- sum(y[[1]])
index <- index + 1
}
write.csv(start_tab, paste0(x, "_start_tab.csv"))
write.csv(start_inf, paste0(x, "_start_inf_hist.csv"))
write.csv(antigenic_map, paste0(x, "_antigenic_map.csv"))
write.csv(titre_dat, paste0(x, "_titre_dat.csv"))
res <- serosolver::run_MCMC(start_tab, titre_dat, antigenic_map,
start_inf_hist=start_inf,filename=x,
CREATE_POSTERIOR_FUNC=create_posterior_func,
CREATE_PRIOR_FUNC = NULL,
version=prior_version,
mcmc_pars=mcmc_pars,
measurement_indices=measurement_indices, ## NULL
measurement_random_effects = TRUE, ## FALSE
solve_likelihood=TRUE)
}
}
