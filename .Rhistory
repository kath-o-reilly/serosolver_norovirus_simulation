# we want to restrict the analysis to those that are "responders"
data$response <- data$x2012_ic50r + data$x2009_ic50r + data$x2006b_ic50r + data$x2002_ic50r
table(data$response)
# compare relative IC50s for specific groups (wip)
data3 <- data %>% filter(response!=0)
data3$date2 <- as.Date(data3$sample_date,origin = "1900-01-01")
data3$mth <- format(data3$date2,"%b")
table(data3$mth)
data4 <- data3 #%>% filter(mth !="Dec" & mth !="Jan" & mth !="Feb" )
tmp <- data3 %>% select(x2012_ic50,x2012_slope,age,mth,yearof_collection)
View(tmp)
res.km <- kmeans(scale(tmp[, -5]), 3, nstart = 25)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_slope <- as.numeric(tmp$x2012_slope)
res.km <- kmeans(scale(tmp[, -5]), 3, nstart = 25)
tmp$mth <- as.numeric(tmp$mth)
data3$mth <- format(data3$date2,"%m")
tmp <- data3 %>% select(x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_slope <- as.numeric(tmp$x2012_slope)
res.km <- kmeans(scale(tmp[, -5]), 3, nstart = 25)
tmp <- tmp[!is.na(tmp$x2012_ic50),]
tmp <- tmp[!is.na(tmp$x2012_slope),]
tmp <- tmp[!is.na(tmp$mth),]
res.km <- kmeans(scale(tmp[, -5]), 3, nstart = 25)
colMeans(tmp)
mean(tmp$x2012_ic50)
mean(tmp$x2012_slope)
mean(tmp$age)
mean(tmp$mth)
!is.na(tmp$mth)
tmp$mth <- as.numeric(tmp$mth)
colMeans(tmp)
res.km <- kmeans(scale(tmp[, -5]), 3, nstart = 25)
fviz_cluster(res.km, data = df[, -5],
#palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
library(ggpubr)
library(factoextra)
fviz_cluster(res.km, data = df[, -5],
#palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
fviz_cluster(res.km, data = tmp[, -5],
#palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
# Dimension reduction using PCA
res.pca <- prcomp(tmp[, -5],  scale = TRUE)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)
# Add Species groups from the original data sett
ind.coord$Species <- tmp$yearof_collection
# Data inspection
head(ind.coord)
# Percentage of variance explained by dimensions
eigenvalue <- round(get_eigenvalue(res.pca), 1)
variance.percent <- eigenvalue$variance.percent
head(eigenvalue)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Species", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) +
stat_mean(aes(color = cluster), size = 4)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "yearof_collection", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) +
stat_mean(aes(color = cluster), size = 4)
View(ind.coord)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Species", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) +
stat_mean(aes(color = cluster), size = 4)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Species", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) #+
# Add Species groups from the original data sett
ind.coord$Species <- as.factor(tmp$yearof_collection)
# Data inspection
head(ind.coord)
# Percentage of variance explained by dimensions
eigenvalue <- round(get_eigenvalue(res.pca), 1)
variance.percent <- eigenvalue$variance.percent
head(eigenvalue)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Species", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) #+
names(data3)
tmp <- data3 %>% select(x2009_ic50,x2009_slope,x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_slope <- as.numeric(tmp$x2012_slope)
tmp$mth <- as.numeric(tmp$mth)
tmp <- data3 %>% select(as.numeric(x2009_ic50),as.numeric(x2009_slope),x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp <- data3 %>% select(x2009_ic50,x2009_slope,x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_slope <- as.numeric(tmp$x2012_slope)
tmp$x2009_ic50 <- as.numeric(tmp$x2009_ic50)
tmp$x2009_slope <- as.numeric(tmp$x2009_slope)
tmp <- tmp[!is.na(tmp$x2012_ic50),]
tmp <- tmp[!is.na(tmp$x2012_slope),]
tmp <- tmp[!is.na(tmp$x2009_ic50),]
tmp <- tmp[!is.na(tmp$x2009_slope),]
tmp <- tmp[!is.na(tmp$mth),]
colMeans(tmp)
tmp$mth <- as.numeric(tmp$mth)
colMeans(tmp)
# Dimension reduction using PCA
res.pca <- prcomp(tmp[, -7],  scale = TRUE)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)
res.km <- kmeans(scale(tmp[, -7]), 5, nstart = 25)
# Dimension reduction using PCA
res.pca <- prcomp(tmp[, -7],  scale = TRUE)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)
# Add Species groups from the original data sett
ind.coord$Year <- as.factor(tmp$yearof_collection)
# Data inspection
head(ind.coord)
# Percentage of variance explained by dimensions
eigenvalue <- round(get_eigenvalue(res.pca), 1)
variance.percent <- eigenvalue$variance.percent
head(eigenvalue)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Year", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) #+
head(data3)
names(data3)
tmp <- data3 %>% select(x2006b_ic50,x2006b_slope,x2009_ic50,x2009_slope,x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp$x2006b_ic50 <- as.numeric(tmp$x2006b_ic50)
tmp$x2006b_slope <- as.numeric(tmp$x2006b_slope)
tmp$mth <- as.numeric(tmp$mth)
tmp <- tmp[!is.na(tmp$x2012_ic50),]
tmp <- tmp[!is.na(tmp$x2012_slope),]
tmp <- tmp[!is.na(tmp$x2009_ic50),]
tmp <- tmp[!is.na(tmp$x2009_slope),]
tmp <- tmp[!is.na(tmp$mth),]
colMeans(tmp)
tmp <- tmp[!is.na(tmp$x2006b_ic50),]
tmp <- tmp[!is.na(tmp$x2006b_slope),]
tmp <- tmp[!is.na(tmp$mth),]
colMeans(tmp)
tmp$mth <- as.numeric(tmp$mth)
tmp <- tmp[!is.na(tmp$x2012_ic50),]
tmp <- tmp[!is.na(tmp$x2012_slope),]
tmp <- tmp[!is.na(tmp$x2009_ic50),]
tmp <- tmp[!is.na(tmp$x2009_slope),]
tmp <- tmp[!is.na(tmp$x2006b_ic50),]
tmp <- tmp[!is.na(tmp$x2006b_slope),]
tmp <- tmp[!is.na(tmp$mth),]
colMeans(tmp)
tmp <- data3 %>% select(x2006b_ic50,x2006b_slope,x2009_ic50,x2009_slope,x2012_ic50,x2012_slope,age,mth,yearof_collection)
tmp$x2012_ic50 <- as.numeric(tmp$x2012_ic50)
tmp$x2012_slope <- as.numeric(tmp$x2012_slope)
tmp$x2009_ic50 <- as.numeric(tmp$x2009_ic50)
tmp$x2009_slope <- as.numeric(tmp$x2009_slope)
tmp$x2006b_ic50 <- as.numeric(tmp$x2006b_ic50)
tmp$x2006b_slope <- as.numeric(tmp$x2006b_slope)
tmp$mth <- as.numeric(tmp$mth)
tmp <- tmp[!is.na(tmp$x2012_ic50),]
tmp <- tmp[!is.na(tmp$x2012_slope),]
tmp <- tmp[!is.na(tmp$x2009_ic50),]
tmp <- tmp[!is.na(tmp$x2009_slope),]
tmp <- tmp[!is.na(tmp$x2006b_ic50),]
tmp <- tmp[!is.na(tmp$x2006b_slope),]
tmp <- tmp[!is.na(tmp$mth),]
colMeans(tmp)
res.km <- kmeans(scale(tmp[, -9]), 5, nstart = 25)
# Dimension reduction using PCA
res.pca <- prcomp(tmp[, -9],  scale = TRUE)
# Coordinates of individuals
ind.coord <- as.data.frame(get_pca_ind(res.pca)$coord)
# Add clusters obtained using the K-means algorithm
ind.coord$cluster <- factor(res.km$cluster)
# Add Species groups from the original data sett
ind.coord$Year <- as.factor(tmp$yearof_collection)
# Data inspection
head(ind.coord)
# Percentage of variance explained by dimensions
eigenvalue <- round(get_eigenvalue(res.pca), 1)
variance.percent <- eigenvalue$variance.percent
head(eigenvalue)
ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Year", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) #+
head(eigenvalue)
# Data inspection
head(ind.coord)
fviz_pca_var(res.pca,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
p1 <- ggscatter(
ind.coord, x = "Dim.1", y = "Dim.2",
color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
shape = "Year", size = 1.5,  legend = "right", ggtheme = theme_bw(),
xlab = paste0("Dim 1 (", variance.percent[1], "% )" ),
ylab = paste0("Dim 2 (", variance.percent[2], "% )" )
) #+
p2 <- fviz_pca_var(res.pca,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
pdf(paste0(out_folder,"pca_summary.pdf"),height=6,width=15)
plot_grid(p1,p2,cols=2)
dev.off()
(62/122)/(54/145)
(10/122)/(16/145)
(137/274)/(143/313)
(137/274)/(26/313)
(27/274)/(26/313)
54/145
1-(1-0.37)**2
1-(1-0.37)**3
2400*3
1-(1-0.37)**4
2400*4
62/122
2400+1800
1-(1-0.51)**2
4200+2400
1-(1-0.51)**3
6600+2400
table(rbinom(1000,4,0.34))
table(rbinom(1000,4,0.22))
install.packages(c("boot", "foreign", "Matrix", "nlme"))
ages <- c(28.1,27.5,25,29.9,29.7,29.9,39.9,33.6,21.3,30.8)
bs1 <- lapply(1:1039, function(i) sample(ages, replace = T))
bs1 <- lapply(1:1039, sample(ages, replace = T))
bs2 <- sapply(1:1039, sample(ages, replace = T))
bs2 <- sapply(1:1039, function(i) sample(ages, replace = T))
View(bs2)
(log(0.5)-log(0.22))/log(0.78)
((log(0.5)-log(0.22))/log(0.78))+1
choose(20,1)
((log(0.5)-log(0.22)-log(choose(3:15,1)))/log(0.78))+1
y <- ((log(0.5)-log(0.22)-log(choose(3:15,1)))/log(0.78))+1
x<-c(3:15)
plot(x,y)
hist(rbinom(100,3,0.22))
hist(rbinom(100,3,0.22),breaks = c(0:3))
table(rbinom(100,3,0.22))/100
table(rbinom(100,6,0.22))/100
table(rbinom(100,9,0.22))/100
table(rbinom(100,9,0.22))/100
table(rbinom(1000,9,0.22))/1000
table(rbinom(1000,6,0.22))/1000
0.46*207000000
library(ggplot2)
library(coda)
library(plyr)
library(reshape2)
library(data.table)
library(foreach)
library(doParallel)
library(parallel)
library(dplyr)
library(readr)
library(viridis)
library(ggpubr)
#library(devtools)
library(misc3d)
library(plot3D)
library(rgl)
#serosolver_wd <- "~/Documents/GitHub/serosolver/"
#devtools::load_all(serosolver_wd)
library(serosolver)
rm(list = ls())
run_name <- "data_test_ac" #"sim_noro_allsampled" #
main_wd <-  "/Users/lsh1603970/GitHub/serosolver_norovirus_simulation" #"~/Documents/norovirus_test/"
chain_wd <- paste0(main_wd,"/chains/",run_name)
save_wd <- paste0(main_wd,"/figures/chain_plots/")
if(!dir.exists(save_wd)) dir.create(save_wd,recursive = TRUE)
if(!dir.exists(chain_wd)) dir.create(chain_wd,recursive = TRUE)
buckets <- 1 ## Ignore
prior_version <- 2 ## Which prior on the infection histories to use? Prior version 2 is generally preferred
n_chains <- 5 ## Number of MCMC chains to run
rerun <- TRUE ## Set to FALSE if you just want to load in previously run chains
setwd(main_wd)
print(paste0("In directory: ", main_wd))
print(paste0("Saving to: ", save_wd))
set.seed(1)
## Run multiple chains in parallel
cl <- makeCluster(n_chains)
registerDoParallel(cl)
## MCMC settings, not super important but can be tweaked
mcmc_pars <- c("save_block"=100,"thin"=100,"thin_hist"=500,"iterations"=100000,
"adaptive_period"=50000,
"burnin"=0,"switch_sample"=2,"hist_switch_prob"=0.05,
"year_swap_propn"=0.8,"swap_propn"=0.5,
"inf_propn"=0.5,"hist_sample_prob"=1,"move_size"=3, "hist_opt"=0,
"popt"=0.44,"popt_hist"=0.44,"opt_freq"=2000,propose_from_prior=TRUE)
## Simulation parameters
n_indivs <- 250
n_groups <- 1 ## Leave as 1, can in theory make multiple groups with distinct FOI parameters, but needs extra setup
n_samps <- 1 ## Number of samples per person
repeats <- 1 ## Number of repeat measurements per variant/sample combination
samp_min <- 2008 ## First sample year
samp_max <- 2012 ## Final sample year
year_min <- 2000 ## First year of possible circulation (ie. time 0 of the simulation)
year_max <- 2012 ## Final year of possible circulation
age_min <- 1 ## Age minimum and maximum in years, simulated from a uniform distribution
age_max <- 7
## Viruses and times for samples
sampled_viruses <- c(2002,2006,2009,2012)
sampling_times <- seq(samp_min, samp_max, by=1)
if(run_name == "data_test_ac"){
antigenic_mapB <- read_csv("antigenic_map_noro_inferred_jump.csv")
oo <- match(sampled_viruses,antigenic_mapB$inf_times)
antigenic_coords <- antigenic_mapB[oo,]
names(antigenic_coords) <- c("X","Y","Strain")
antigenic_map <- (read_csv("antigenic_map_noro_inferred_trueequal.csv")) #
}
if(run_name == "data_test_ac2"){
antigenic_mapB <- read_csv("antigenic_map_noro_inferred_jump.csv")
oo <- match(sampled_viruses,antigenic_mapB$inf_times)
antigenic_coords <- antigenic_mapB[oo,]
names(antigenic_coords) <- c("X","Y","Strain")
antigenic_map <- antigenic_mapB #as.data.frame(read_csv("antigenic_map_noro_inferred_temporal.csv")) #
}
if(run_name != "data_test_ac2" & run_name != "data_test_ac"){
## Create a fake antigenic map -- can put in what you like here
antigenic_coords <- data.frame(Strain=c(2000,2002,2006,2009,2012),X=c(0,0.5,3,3.5,4),Y=c(0,2,1,3,4))
antigenic_map <- generate_antigenic_map_flexible(antigenic_coords,
year_max=2013,year_min=2000,spar = 0.001)
}
ggplot(data=antigenic_map,aes(x=x_coord,y=y_coord)) + geom_line() +
geom_text(aes(x=x_coord+0.5,y=y_coord,label=inf_times)) +
geom_point(data=antigenic_coords,aes(x=X,y=Y),col="blue") +
geom_text(data=antigenic_coords,aes(x=X+0.5,y=Y,label=Strain),col="blue")
strain_isolation_times <- antigenic_map$inf_times
n_times <- length(strain_isolation_times)
## Set up parameter table
par_tab <- read.csv("par_tab_base.csv",stringsAsFactors=FALSE)
par_tab <- par_tab[par_tab$names != "phi",]
hist(rbeta(1000,2,1))
hist(rbeta(1000,1,2))
par_tab[par_tab$names == c("alpha","beta"),c("values")] <- c(1,2) ## Can also try c(1,1), or something informative. Just the parameters of a beta distribution which acts as the prior on the per-time attack rate.
## Just some setup of the parameter table to get parameters vaguely like you showed me
par_tab$fixed <- 1
par_tab[par_tab$names %in% c("mu","mu_short","wane","sigma1","sigma2","tau","error"),"fixed"] <- 0
par_tab[par_tab$names %in% c("mu","mu_short","wane","sigma1","sigma2","tau","error"),"values"] <- c(2,5,0.4,0.1,0.01,0.5,1)
## Create some random measurement offsets -- these add a systematic shift to each observed variant. Only those sampled variant years have offsets, the rest are 0
## These are unknown parameters to be estimated, assuming the offsets are drawn from ~ norm(0, 1)
par_tab_rhos <- data.frame(names="rho",values=rep(0,n_times),fixed=1,steps=0.1,
lower_bound=-3,upper_bound=3,lower_start=-1,
upper_start=1,type=3)
par_tab_rhos[which(strain_isolation_times%in%sampled_viruses),"values"] <- rnorm(length(sampled_viruses), 1)
par_tab_rhos[which(strain_isolation_times%in%sampled_viruses),"fixed"] <-0
measurement_indices <- seq_along(strain_isolation_times)
par_tab <- bind_rows(par_tab, par_tab_rhos)
## Simulate realistic-ish attack rates
attack_rates <- simulate_attack_rates(strain_isolation_times, 0.15,1,FALSE)
attack_rates[attack_rates>1] <- 1
plot(strain_isolation_times,attack_rates,pch=19)
## Simulate the data
sim_data <- simulate_data(par_tab=par_tab, group=1, n_indiv=n_indivs,
buckets=buckets,
strain_isolation_times=strain_isolation_times,
measured_strains=sampled_viruses,
sampling_times=sampling_times, nsamps=n_samps,
antigenic_map=antigenic_map,
titre_sensoring=0.2, ## Randomly censor 20% of measurements
age_min=age_min,age_max=age_max,
attack_rates=attack_rates, repeats=repeats,
mu_indices = NULL, measurement_indices = measurement_indices,
add_noise=TRUE)
sum(sim_data$infection_histories)
plot_data(sim_data$data,sim_data$infection_histories,strain_isolation_times,n_indivs=10)
titre_dat <- sim_data$data %>% tidyr::drop_na()
titre_dat <- titre_dat %>% group_by(individual, samples, virus) %>% mutate(run=1:n()) %>% ungroup()
titre_dat <- titre_dat %>% left_join(sim_data$ages)
titre_dat <- titre_dat %>% arrange(individual, samples, virus, run) %>% as.data.frame()
ggplot(titre_dat,aes(x=samples,y=titre,group=samples)) + geom_boxplot() + facet_wrap(~virus)
## Save titre data
write_csv(titre_dat, file=paste0(save_wd,"/",run_name,"_titre_data.csv"))
## Save parameter table
write_csv(par_tab, file=paste0(save_wd,"/",run_name,"_par_tab.csv"))
## Save attack rates
write_csv(sim_data$attack_rates, file=paste0(save_wd,"/",run_name,"_attack_rates.csv"))
## Save infection histories
write_csv(as.data.frame(sim_data$infection_histories), file=paste0(save_wd,"/",run_name,"_infection_histories.csv"))
head(titre_dat)
table(samp=titre_dat$samples,virus=titre_dat$virus)
f <- create_posterior_func(par_tab,titre_dat,antigenic_map=antigenic_map,strain_isolation_times = strain_isolation_times,
version=prior_version,solve_likelihood=TRUE,n_alive=NULL,
measurement_indices_by_time=measurement_indices ## NULL
)
# check which parameters we are estimating
par_tab[par_tab$fixed==0,]
t1 <- Sys.time()
filenames <- paste0(chain_wd, "/",run_name, "_",1:n_chains)
if(rerun){
res <- foreach(x = filenames, .packages = c('serosolver','data.table','plyr',"dplyr")) %dopar% {
devtools::load_all(save_wd)
index <- 1
lik <- -Inf
inf_hist_correct <- 1
while((!is.finite(lik) || inf_hist_correct > 0) & index < 100){
start_tab <- generate_start_tab(par_tab)
start_inf <- setup_infection_histories_total(titre_dat,strain_isolation_times,2,3)
inf_hist_correct <- sum(check_inf_hist(titre_dat, strain_isolation_times, start_inf))
y <- f(start_tab$values, start_inf)
lik <- sum(y[[1]])
index <- index + 1
}
write.csv(start_tab, paste0(x, "_start_tab.csv"))
write.csv(start_inf, paste0(x, "_start_inf_hist.csv"))
write.csv(antigenic_map, paste0(x, "_antigenic_map.csv"))
write.csv(titre_dat, paste0(x, "_titre_dat.csv"))
res <- serosolver::run_MCMC(start_tab, titre_dat, antigenic_map,
start_inf_hist=start_inf,filename=x,
CREATE_POSTERIOR_FUNC=create_posterior_func,
CREATE_PRIOR_FUNC = NULL,
version=prior_version,
mcmc_pars=mcmc_pars,
measurement_indices=measurement_indices, ## NULL
measurement_random_effects = TRUE, ## FALSE
solve_likelihood=TRUE)
}
}
run_time_fast <- Sys.time() - t1
run_time_fast # 20 mins.
## Read in chains for trace plot
chains <- load_mcmc_chains(chain_wd,convert_mcmc=TRUE,burnin = mcmc_pars["adaptive_period"],unfixed = TRUE)
pdf(paste0(save_wd,"/",run_name,"_chain.pdf"))
plot(as.mcmc.list(chains$theta_list_chains))
dev.off()
paste0(save_wd,"/",run_name,"_chain.pdf")
## Read in chains for all other plots
chains <- load_mcmc_chains(chain_wd,convert_mcmc=FALSE,burnin = mcmc_pars["adaptive_period"],unfixed = FALSE)
chain <- as.data.frame(chains$theta_chain)
inf_chain <- chains$inf_chain
#summary stats
library(coda)
list_chains1 <- chains[[1]]
tmp <- summary(chain[,c("mu","sigma1",
"tau",
#"wane",
"error","total_infections",
"lnlike","prior_prob")])
tmp
# how well do we re-estimate parameters?
df2 <- data.frame(variable=c("mu","tau","sigma1","error"),value=c(3,0.5,0.2,2))
p1 <- list_chains1 %>% select(mu,tau,sigma1,error) %>% tidyr::gather(variable, value) %>%
ggplot(aes(value)) + geom_histogram(bins = 51) +
geom_vline(data=df2,aes(xintercept=value),col="red") +
facet_wrap(~variable, scales = 'free_x')
p1
# how well do we re-estimate parameters?
df2 <- data.frame(variable=c("mu","mu_short","tau","sigma1","sigma2","wane","error"),value=c(3,0.5,0.2,2))
# check which parameters we are estimating
par_tab[par_tab$fixed==0,]
# how well do we re-estimate parameters?
df2 <- data.frame(variable=c("mu","mu_short","tau","sigma1","sigma2","wane","error"),
value=c(2,5,0.4,0.1,1))
# how well do we re-estimate parameters?
df2 <- data.frame(variable=c("mu","mu_short","tau","sigma1","sigma2","wane","error"),
value=c(2,5,0.4,0.01,0.5,0.1,1))
p1 <- list_chains1 %>% select(mu,tau,sigma1,error) %>% tidyr::gather(variable, value) %>%
ggplot(aes(value)) + geom_histogram(bins = 51) +
geom_vline(data=df2,aes(xintercept=value),col="red") +
facet_wrap(~variable, scales = 'free_x')
p1
p1 <- list_chains1 %>% select(mu,mu_short,tau,sigma1,sigma2,wane,error) %>% tidyr::gather(variable, value) %>%
ggplot(aes(value)) + geom_histogram(bins = 51) +
geom_vline(data=df2,aes(xintercept=value),col="red") +
facet_wrap(~variable, scales = 'free_x')
p1
